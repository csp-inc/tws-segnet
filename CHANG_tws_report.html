<!DOCTYPE html>
<!-- saved from url=(0022)http://localhost:6419/ -->
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  
  <title>report.md - Grip</title>
  <link rel="icon" href="http://localhost:6419/__/grip/static/favicon.ico">
  <link rel="stylesheet" href="./CHANG_twsreport_nov_2017_files/frameworks-d7137690e30123bade38abb082ac79f36cc7a105ff92e602405f53b725465cab.css">
  <link rel="stylesheet" href="./CHANG_twsreport_nov_2017_files/site-cd79f063f6da2fef8de0055aa11c913cc1873486fc05ade3227e0cbcc7a168c6.css">
  <link rel="stylesheet" href="./CHANG_twsreport_nov_2017_files/github-15d10d5c5d04521a59aed66ac12ddf49a051df082e9488bf8241b716e792d414.css">
  <link rel="stylesheet" href="./CHANG_twsreport_nov_2017_files/octicons.css">
  <style>
    /* Page tweaks */
    .preview-page {
      margin-top: 64px;
    }
    /* User-content tweaks */
    .timeline-comment-wrapper > .timeline-comment:after,
    .timeline-comment-wrapper > .timeline-comment:before {
      content: none;
    }
    /* User-content overrides */
    .discussion-timeline.wide {
      width: 920px;
    }
  </style>
<script type="text/javascript" src="./CHANG_twsreport_nov_2017_files/MathJax.js"></script><style type="text/css">.MathJax_Hover_Frame {border-radius: .25em; -webkit-border-radius: .25em; -moz-border-radius: .25em; -khtml-border-radius: .25em; box-shadow: 0px 0px 15px #83A; -webkit-box-shadow: 0px 0px 15px #83A; -moz-box-shadow: 0px 0px 15px #83A; -khtml-box-shadow: 0px 0px 15px #83A; border: 1px solid #A6D ! important; display: inline-block; position: absolute}
.MathJax_Menu_Button .MathJax_Hover_Arrow {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 4px; -webkit-border-radius: 4px; -moz-border-radius: 4px; -khtml-border-radius: 4px; font-family: 'Courier New',Courier; font-size: 9px; color: #F0F0F0}
.MathJax_Menu_Button .MathJax_Hover_Arrow span {display: block; background-color: #AAA; border: 1px solid; border-radius: 3px; line-height: 0; padding: 4px}
.MathJax_Hover_Arrow:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_Hover_Arrow:hover span {background-color: #CCC!important}
</style><style type="text/css">#MathJax_About {position: fixed; left: 50%; width: auto; text-align: center; border: 3px outset; padding: 1em 2em; background-color: #DDDDDD; color: black; cursor: default; font-family: message-box; font-size: 120%; font-style: normal; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; border-radius: 15px; -webkit-border-radius: 15px; -moz-border-radius: 15px; -khtml-border-radius: 15px; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_About.MathJax_MousePost {outline: none}
.MathJax_Menu {position: absolute; background-color: white; color: black; width: auto; padding: 5px 0px; border: 1px solid #CCCCCC; margin: 0; cursor: default; font: menu; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; border-radius: 5px; -webkit-border-radius: 5px; -moz-border-radius: 5px; -khtml-border-radius: 5px; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
.MathJax_MenuItem {padding: 1px 2em; background: transparent}
.MathJax_MenuArrow {position: absolute; right: .5em; padding-top: .25em; color: #666666; font-size: .75em}
.MathJax_MenuActive .MathJax_MenuArrow {color: white}
.MathJax_MenuArrow.RTL {left: .5em; right: auto}
.MathJax_MenuCheck {position: absolute; left: .7em}
.MathJax_MenuCheck.RTL {right: .7em; left: auto}
.MathJax_MenuRadioCheck {position: absolute; left: .7em}
.MathJax_MenuRadioCheck.RTL {right: .7em; left: auto}
.MathJax_MenuLabel {padding: 1px 2em 3px 1.33em; font-style: italic}
.MathJax_MenuRule {border-top: 1px solid #DDDDDD; margin: 4px 3px}
.MathJax_MenuDisabled {color: GrayText}
.MathJax_MenuActive {background-color: #606872; color: white}
.MathJax_MenuDisabled:focus, .MathJax_MenuLabel:focus {background-color: #E8E8E8}
.MathJax_ContextMenu:focus {outline: none}
.MathJax_ContextMenu .MathJax_MenuItem:focus {outline: none}
#MathJax_AboutClose {top: .2em; right: .2em}
.MathJax_Menu .MathJax_MenuClose {top: -10px; left: -10px}
.MathJax_MenuClose {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; font-family: 'Courier New',Courier; font-size: 24px; color: #F0F0F0}
.MathJax_MenuClose span {display: block; background-color: #AAA; border: 1.5px solid; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; line-height: 0; padding: 8px 0 6px}
.MathJax_MenuClose:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_MenuClose:hover span {background-color: #CCC!important}
.MathJax_MenuClose:hover:focus {outline: none}
</style><style type="text/css">.MathJax_Preview .MJXf-math {color: inherit!important}
</style><style type="text/css">.MJX_Assistive_MathML {position: absolute!important; top: 0; left: 0; clip: rect(1px, 1px, 1px, 1px); padding: 1px 0 0 0!important; border: 0!important; height: 1px!important; width: 1px!important; overflow: hidden!important; display: block!important; -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none}
.MJX_Assistive_MathML.MJX_Assistive_MathML_Block {width: 100%!important}
</style><style type="text/css">#MathJax_Zoom {position: absolute; background-color: #F0F0F0; overflow: auto; display: block; z-index: 301; padding: .5em; border: 1px solid black; margin: 0; font-weight: normal; font-style: normal; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; -webkit-box-sizing: content-box; -moz-box-sizing: content-box; box-sizing: content-box; box-shadow: 5px 5px 15px #AAAAAA; -webkit-box-shadow: 5px 5px 15px #AAAAAA; -moz-box-shadow: 5px 5px 15px #AAAAAA; -khtml-box-shadow: 5px 5px 15px #AAAAAA; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_ZoomOverlay {position: absolute; left: 0; top: 0; z-index: 300; display: inline-block; width: 100%; height: 100%; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
#MathJax_ZoomFrame {position: relative; display: inline-block; height: 0; width: 0}
#MathJax_ZoomEventTrap {position: absolute; left: 0; top: 0; z-index: 302; display: inline-block; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
</style><style type="text/css">.MathJax_Preview {color: #888}
#MathJax_Message {position: fixed; left: 1em; bottom: 1.5em; background-color: #E6E6E6; border: 1px solid #959595; margin: 0px; padding: 2px 8px; z-index: 102; color: black; font-size: 80%; width: auto; white-space: nowrap}
#MathJax_MSIE_Frame {position: absolute; top: 0; left: 0; width: 0px; z-index: 101; border: 0px; margin: 0px; padding: 0px}
.MathJax_Error {color: #CC0000; font-style: italic}
</style><style type="text/css">.MJXp-script {font-size: .8em}
.MJXp-right {-webkit-transform-origin: right; -moz-transform-origin: right; -ms-transform-origin: right; -o-transform-origin: right; transform-origin: right}
.MJXp-bold {font-weight: bold}
.MJXp-italic {font-style: italic}
.MJXp-scr {font-family: MathJax_Script,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-frak {font-family: MathJax_Fraktur,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-sf {font-family: MathJax_SansSerif,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-cal {font-family: MathJax_Caligraphic,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-mono {font-family: MathJax_Typewriter,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-largeop {font-size: 150%}
.MJXp-largeop.MJXp-int {vertical-align: -.2em}
.MJXp-math {display: inline-block; line-height: 1.2; text-indent: 0; font-family: 'Times New Roman',Times,STIXGeneral,serif; white-space: nowrap; border-collapse: collapse}
.MJXp-display {display: block; text-align: center; margin: 1em 0}
.MJXp-math span {display: inline-block}
.MJXp-box {display: block!important; text-align: center}
.MJXp-box:after {content: " "}
.MJXp-rule {display: block!important; margin-top: .1em}
.MJXp-char {display: block!important}
.MJXp-mo {margin: 0 .15em}
.MJXp-mfrac {margin: 0 .125em; vertical-align: .25em}
.MJXp-denom {display: inline-table!important; width: 100%}
.MJXp-denom > * {display: table-row!important}
.MJXp-surd {vertical-align: top}
.MJXp-surd > * {display: block!important}
.MJXp-script-box > *  {display: table!important; height: 50%}
.MJXp-script-box > * > * {display: table-cell!important; vertical-align: top}
.MJXp-script-box > *:last-child > * {vertical-align: bottom}
.MJXp-script-box > * > * > * {display: block!important}
.MJXp-mphantom {visibility: hidden}
.MJXp-munderover {display: inline-table!important}
.MJXp-over {display: inline-block!important; text-align: center}
.MJXp-over > * {display: block!important}
.MJXp-munderover > * {display: table-row!important}
.MJXp-mtable {vertical-align: .25em; margin: 0 .125em}
.MJXp-mtable > * {display: inline-table!important; vertical-align: middle}
.MJXp-mtr {display: table-row!important}
.MJXp-mtd {display: table-cell!important; text-align: center; padding: .5em 0 0 .5em}
.MJXp-mtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-mlabeledtr {display: table-row!important}
.MJXp-mlabeledtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mlabeledtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 1px 3px; font-style: normal; font-size: 90%}
.MJXp-scale0 {-webkit-transform: scaleX(.0); -moz-transform: scaleX(.0); -ms-transform: scaleX(.0); -o-transform: scaleX(.0); transform: scaleX(.0)}
.MJXp-scale1 {-webkit-transform: scaleX(.1); -moz-transform: scaleX(.1); -ms-transform: scaleX(.1); -o-transform: scaleX(.1); transform: scaleX(.1)}
.MJXp-scale2 {-webkit-transform: scaleX(.2); -moz-transform: scaleX(.2); -ms-transform: scaleX(.2); -o-transform: scaleX(.2); transform: scaleX(.2)}
.MJXp-scale3 {-webkit-transform: scaleX(.3); -moz-transform: scaleX(.3); -ms-transform: scaleX(.3); -o-transform: scaleX(.3); transform: scaleX(.3)}
.MJXp-scale4 {-webkit-transform: scaleX(.4); -moz-transform: scaleX(.4); -ms-transform: scaleX(.4); -o-transform: scaleX(.4); transform: scaleX(.4)}
.MJXp-scale5 {-webkit-transform: scaleX(.5); -moz-transform: scaleX(.5); -ms-transform: scaleX(.5); -o-transform: scaleX(.5); transform: scaleX(.5)}
.MJXp-scale6 {-webkit-transform: scaleX(.6); -moz-transform: scaleX(.6); -ms-transform: scaleX(.6); -o-transform: scaleX(.6); transform: scaleX(.6)}
.MJXp-scale7 {-webkit-transform: scaleX(.7); -moz-transform: scaleX(.7); -ms-transform: scaleX(.7); -o-transform: scaleX(.7); transform: scaleX(.7)}
.MJXp-scale8 {-webkit-transform: scaleX(.8); -moz-transform: scaleX(.8); -ms-transform: scaleX(.8); -o-transform: scaleX(.8); transform: scaleX(.8)}
.MJXp-scale9 {-webkit-transform: scaleX(.9); -moz-transform: scaleX(.9); -ms-transform: scaleX(.9); -o-transform: scaleX(.9); transform: scaleX(.9)}
.MathJax_PHTML .noError {vertical-align: ; font-size: 90%; text-align: left; color: black; padding: 1px 3px; border: 1px solid}
</style></head>
<body><div id="MathJax_Message" style="display: none;"></div>
  <div class="page">
    <div id="preview-page" class="preview-page" data-autorefresh-url="/__/grip/refresh/">

    

      <div role="main" class="main-content">
        <div class="container new-discussion-timeline experiment-repo-nav">
          <div class="repository-content">
            <div id="readme" class="readme boxed-group clearfix announce instapaper_body md">
              
                <h3>
                  <span class="octicon octicon-book"></span>
                  report.md
                </h3>
              
              <article class="markdown-body entry-content" itemprop="text" id="grip-content"><p><a href="https://camo.githubusercontent.com/5ad2c29deaa8b9e7d55fc3eb283b02ff400b4e0f/68747470733a2f2f6c68352e676f6f676c6575736572636f6e74656e742e636f6d2f35764e786573715f2d316c534877734f743531325853456d5770753733366e39514730514b3330766378546739746a6e5f49572d69706d5f73523272746c777530455a425059547976616f6f7956366b556839693d773935302d68393739" target="_blank"><img src="./CHANG_twsreport_nov_2017_files/5vNxesq_-1lSHwsOt512XSEmWpu736n9QG0QK30vcxTg9tjn_IW-ipm_sR2rtlwu0EZBPYTyvaooyV6kUh9i=w950-h979" alt="csp" data-canonical-src="https://lh5.googleusercontent.com/5vNxesq_-1lSHwsOt512XSEmWpu736n9QG0QK30vcxTg9tjn_IW-ipm_sR2rtlwu0EZBPYTyvaooyV6kUh9i=w950-h979" style="max-width:100%;"></a></p>
<h1>
<a id="user-content-the-wilderness-society---linear-features-identification" class="anchor" href="http://localhost:6419/#the-wilderness-society---linear-features-identification" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>The Wilderness Society - Linear features identification</h1>
<h3>
<a id="user-content-author-tony-chang" class="anchor" href="http://localhost:6419/#author-tony-chang" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Author: Tony Chang</h3>
<h3>
<a id="user-content-institution-conservation-science-partners" class="anchor" href="http://localhost:6419/#institution-conservation-science-partners" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Institution: Conservation Science Partners</h3>
<h3>
<a id="user-content-project-title-forest-disturbance-detection-and-hydrologic-response-in-the-western-us" class="anchor" href="http://localhost:6419/#project-title-forest-disturbance-detection-and-hydrologic-response-in-the-western-us" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Project title: Forest disturbance detection and hydrologic response in the Western US</h3>
<h5>
<a id="user-content-abstract-the-goal-of-this-project-is-to-identify-road-features-within-blm-areas-from-aerial-based-imagery-to-optimize-efforts-for-determination-of-human-modified-regions-and-untracked-land-in-this-initial-scoping-we-explore-the-usage-of-generative-adversarial-networks-gan-a-recent-innovation-in-the-field-of-deep-learning-that-is-capable-of-style-transfer-we-propose-to-implement-pix2pix-a-recently-released-version-of-this-gan-methodology-for-application-in-road-feature-identification-current-results-are-preliminary-and-display-both-promise-and-deficiencies-in-successful-model-training" class="anchor" href="http://localhost:6419/#abstract-the-goal-of-this-project-is-to-identify-road-features-within-blm-areas-from-aerial-based-imagery-to-optimize-efforts-for-determination-of-human-modified-regions-and-untracked-land-in-this-initial-scoping-we-explore-the-usage-of-generative-adversarial-networks-gan-a-recent-innovation-in-the-field-of-deep-learning-that-is-capable-of-style-transfer-we-propose-to-implement-pix2pix-a-recently-released-version-of-this-gan-methodology-for-application-in-road-feature-identification-current-results-are-preliminary-and-display-both-promise-and-deficiencies-in-successful-model-training" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Abstract: The goal of this project is to identify road features within BLM areas from aerial based imagery to optimize efforts for determination of human modified regions and untracked land. In this initial scoping, we explore the usage of Generative Adversarial Networks (GAN), a recent innovation in the field of Deep Learning, that is capable of "style transfer". We propose to implement Pix2Pix a recently released version of this GAN methodology for application in road feature identification. Current results are preliminary and display both promise and deficiencies in successful model training.</h5>
<h3>
<a id="user-content-method" class="anchor" href="http://localhost:6419/#method" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Method:</h3>
<ol>
<li>Acquire tiled images of remote sensed imagery and matching stylized vector tile.</li>
<li>Use paired styled images as training data for Pix2Pix GAN model.</li>
<li>Optimize training to reduce both Generator and Discriminator networks.</li>
<li>Initial validation through first order visual analysis.</li>
<li>Future accuracy assessment using Jaccard Similarity/Index</li>
</ol>
<h3>
<a id="user-content-introduction" class="anchor" href="http://localhost:6419/#introduction" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Introduction:</h3>
<p>We implemented the pix2pix conditional adversarial networks as a general-purpose solution to image-to-image translation problems for our case of road feature translation <a href="https://arxiv.org/pdf/1611.07004v1.pdf">Isola et al 2016</a>.
This genre of machine learning has displayed early success in urban center satellite image translation to OpenStreetMaps style (photo -&gt; map). Although trials of pix2pix outputs on perceptual validation (human test subjects) were only successful at fooling individuals 6.1% of the time; our goals are not to fool human subjects, but to determine regions within the landscape which could be classified as containing human modified features such as roads. Our intuition of this application is to fit a GAN model that can be used to predict potential road class pixels across numerous high resolution images and reduce specialist time/effort of manual scanning.</p>
<p><strong>Overview of algorithm design and mechanics:
<a href="https://affinelayer.com/pix2pix/">pix2pix-method-document</a></strong></p>
<p><strong>Repository of pix2pix model:
<a href="https://github.com/affinelayer/pix2pix-tensorflow">pix2pix-repository</a></strong></p>
<h3>
<a id="user-content-pilot-training-and-testing" class="anchor" href="http://localhost:6419/#pilot-training-and-testing" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Pilot training and testing:</h3>
<p>Early steps were performed to verify if model could be utilized to predict road features on a complex urban landscape containing numerous feature classes that include buildings, green areas, and various road types. This is demonstrated below with a training model using 3000 images over 3084 epochs (training cycle iterations of random sampling with replacement/image augmentation).</p>
<p><strong>Example model training movie on urban landscape: <a href="https://youtu.be/g5tTgevppWw">CSP-pix2pix-training-movie</a></strong></p>
<h3>
<a id="user-content-results" class="anchor" href="http://localhost:6419/#results" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Results:</h3>
<p>Current results are <em><em>mixed</em></em>.</p>
<h4>
<a id="user-content-early-application-results-on-northwestern-colorado-region" class="anchor" href="http://localhost:6419/#early-application-results-on-northwestern-colorado-region" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Early application results on Northwestern Colorado region:</h4>
<h4>
<a id="user-content-sample-output-1" class="anchor" href="http://localhost:6419/#sample-output-1" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Sample output 1</h4>
<p><a href="https://camo.githubusercontent.com/4948cf4b71000a5aaaf57732f65858825122d189/68747470733a2f2f6c68362e676f6f676c6575736572636f6e74656e742e636f6d2f5f794f5a516c2d72514856475147677a6f666b6542524a416c41667a59344a646670396570424637305a3767314754336e735058356c596f585a75645131484c475f39486d6452717742636672782d38545068693d773935302d683937392d7277" target="_blank"><img src="./CHANG_twsreport_nov_2017_files/_yOZQl-rQHVGQGgzofkeBRJAlAfzY4Jdfp9epBF70Z7g1GT3nsPX5lYoXZudQ1HLG_9HmdRqwBcfrx-8TPhi=w950-h979-rw" alt="pix2pix-sample1" data-canonical-src="https://lh6.googleusercontent.com/_yOZQl-rQHVGQGgzofkeBRJAlAfzY4Jdfp9epBF70Z7g1GT3nsPX5lYoXZudQ1HLG_9HmdRqwBcfrx-8TPhi=w950-h979-rw" style="max-width:100%;"></a></p>
<h4>
<a id="user-content-sample-output-2" class="anchor" href="http://localhost:6419/#sample-output-2" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Sample output 2</h4>
<p><a href="https://camo.githubusercontent.com/ae2285dc403cba6501f98f6f69cc9e95a615ed11/68747470733a2f2f6c68332e676f6f676c6575736572636f6e74656e742e636f6d2f7050496d313855664b6e76346558313168355f5a4655615634726c744542504a4d6769707462646b7a7a6f6c58717a394f5145733837646c3733327a6d54634b574e34356e31734f4546727a634c62624c4477593d773935302d683937392d7277" target="_blank"><img src="./CHANG_twsreport_nov_2017_files/pPIm18UfKnv4eX11h5_ZFUaV4rltEBPJMgiptbdkzzolXqz9OQEs87dl732zmTcKWN45n1sOEFrzcLbbLDwY=w950-h979-rw" alt="pix2pix-sample2" data-canonical-src="https://lh3.googleusercontent.com/pPIm18UfKnv4eX11h5_ZFUaV4rltEBPJMgiptbdkzzolXqz9OQEs87dl732zmTcKWN45n1sOEFrzcLbbLDwY=w950-h979-rw" style="max-width:100%;"></a></p>
<ul>
<li>
<p>Difficulty arises in the training due to <a href="http://aiden.nibali.org/blog/2017-01-18-mode-collapse-gans/">mode collapse</a>, a common issue in GAN models <a href="https://arxiv.org/pdf/1701.00160v3.pdf">Goodfellow 2017</a>.</p>
<ul>
<li>Using ~2m pixel resolution for a 600x600 (1.5km) tile.</li>
<li>Current training dataset 2000 tiles.</li>
</ul>
</li>
<li>
<p>Next iteration for the remainder of the month (November 2017):</p>
<ul>
<li>Use ~1m resolution pixels for a 500x500 (500m) tile.</li>
<li>Incorporate more variance in training data (more class color labels).</li>
<li>Increase sample size to 10000 tiles.</li>
<li>Predict over the Rock Springs, WY area.</li>
</ul>
</li>
</ul>
<h3>
<a id="user-content-next-steps" class="anchor" href="http://localhost:6419/#next-steps" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Next steps:</h3>
<ul>
<li>Attempt to optimize pix2pix model with more robust training data set of more tiles.</li>
<li>If unable to produce highly accurate classified road maps, use a threshold measure of pix2pix model predicted road pixels to indicate level of <em><em>potential</em></em> human road impact within an aggregated 1km area. After combine with auxiliary data that may include urban sprawl, agriculture, energy development, and transportation layers.</li>
</ul>
</article>
            </div>
          </div>
        </div>
      </div>

    

  </div>
  <div>&nbsp;</div>
  </div><script>
    function showCanonicalImages() {
      var images = document.getElementsByTagName('img');
      if (!images) {
        return;
      }
      for (var index = 0; index < images.length; index++) {
        var image = images[index];
        if (image.getAttribute('data-canonical-src') && image.src !== image.getAttribute('data-canonical-src')) {
          image.src = image.getAttribute('data-canonical-src');
        }
      }
    }

    function scrollToHash() {
      if (location.hash && !document.querySelector(':target')) {
        var element = document.getElementById('user-content-' + location.hash.slice(1));
        if (element) {
           element.scrollIntoView();
        }
      }
    }

    function autorefreshContent(eventSourceUrl) {
      var initialTitle = document.title;
      var contentElement = document.getElementById('grip-content');
      var source = new EventSource(eventSourceUrl);
      var isRendering = false;

      source.onmessage = function(ev) {
        var msg = JSON.parse(ev.data);
        if (msg.updating) {
          isRendering = true;
          document.title = '(Rendering) ' + document.title;
        } else {
          isRendering = false;
          document.title = initialTitle;
          contentElement.innerHTML = msg.content;
          showCanonicalImages();
        }
      }

      source.onerror = function(e) {
        if (e.readyState === EventSource.CLOSED && isRendering) {
          isRendering = false;
          document.title = initialTitle;
        }
      }
    }

    window.onhashchange = function() {
      scrollToHash();
    }

    window.onload = function() {
      scrollToHash();
    }

    showCanonicalImages();

    var autorefreshUrl = document.getElementById('preview-page').getAttribute('data-autorefresh-url');
    if (autorefreshUrl) {
      autorefreshContent(autorefreshUrl);
    }
  </script>

</body></html>